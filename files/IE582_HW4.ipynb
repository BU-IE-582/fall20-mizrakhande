{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DERMATOLOGY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'dermatology_data.txt'\n",
    "data = np.loadtxt(filename, delimiter=',', skiprows=1, dtype=str)\n",
    "data= pd.DataFrame(data)\n",
    "missing_values=np.where(data.iloc[:,:]=='?')\n",
    "data=data.drop(missing_values[0])\n",
    "data.astype('int')\n",
    "\n",
    "\n",
    "features=data.columns[0:34]\n",
    "X = data.loc[:,features]\n",
    "y = data.loc[:,34].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    #print('Model Performance')\n",
    "    print('Improved Accuracy = %',metrics.accuracy_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree for Dermatology Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for base model DT: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "model1 = DecisionTreeClassifier(random_state=0)\n",
    "model1.fit(X_train, y_train)\n",
    "y_test_pred=model1.predict(X_test)\n",
    "#Score the model\n",
    "print(\"Accuracy for base model DT:\",metrics.accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning for DT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 8, 'min_samples_leaf': 3}\n",
      "Best score of the best model on training data: 0.96\n",
      "Improved Accuracy = % 0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "parameters = {'max_depth':[2,3,8,10], 'min_samples_leaf':[2,3,4,5]}\n",
    "\n",
    "tuning1 = GridSearchCV(estimator =DecisionTreeClassifier(random_state=10), \n",
    "            param_grid = parameters, scoring='accuracy',n_jobs=4, cv=5)\n",
    "tuning1.fit(X_train,y_train)\n",
    "\n",
    "print(tuning1.best_params_)\n",
    "print(\"Best score of the best model on training data:\",tuning1.best_score_)\n",
    "best_model1 = tuning1.best_estimator_\n",
    "best_model1_accuracy1 = evaluate(best_model1, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest for Dermatology Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for base model RF: 0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "model2=RandomForestClassifier(random_state=0)\n",
    "model2.fit(X_train, y_train)\n",
    "y_train_pred2=model2.predict(X_train)\n",
    "y_test_pred2=model2.predict(X_test)\n",
    "\n",
    "# Score the model\n",
    "print(\"Accuracy for base model RF:\",metrics.accuracy_score(y_test, y_test_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 6}\n",
      "Best score of the best model on training data: 0.9677551020408164\n",
      "Improved Accuracy = % 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "a=len(X.columns)\n",
    "b=round(math.sqrt(len(X.columns)))\n",
    "c=round((len(X.columns))/3)\n",
    "parameters = {'max_features': [a,b,c]}\n",
    "\n",
    "tuning2 = GridSearchCV(estimator=RandomForestClassifier(n_estimators=500,min_samples_leaf=5, random_state=0), \n",
    "            param_grid = parameters, scoring='accuracy',n_jobs=4, cv=5)\n",
    "tuning2.fit(X_train,y_train)\n",
    "\n",
    "print(tuning2.best_params_)\n",
    "print(\"Best score of the best model on training data:\",tuning2.best_score_)\n",
    "\n",
    "best_model2 = tuning2.best_estimator_\n",
    "best_model2_accuracy2 = evaluate(best_model2, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penalized Regression for Dermatology Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.0001\n",
      "Training accuracy for RPA: 0.3453815261044177\n",
      "Test accuracy for RPA: 0.23148148148148148\n",
      "\n",
      "C: 0.00035938136638046257\n",
      "Training accuracy for RPA: 0.3453815261044177\n",
      "Test accuracy for RPA: 0.23148148148148148\n",
      "\n",
      "C: 0.001291549665014884\n",
      "Training accuracy for RPA: 0.3453815261044177\n",
      "Test accuracy for RPA: 0.23148148148148148\n",
      "\n",
      "C: 0.004641588833612782\n",
      "Training accuracy for RPA: 0.3453815261044177\n",
      "Test accuracy for RPA: 0.23148148148148148\n",
      "\n",
      "C: 0.016681005372000592\n",
      "Training accuracy for RPA: 0.6265060240963856\n",
      "Test accuracy for RPA: 0.48148148148148145\n",
      "\n",
      "C: 0.05994842503189409\n",
      "Training accuracy for RPA: 0.8875502008032129\n",
      "Test accuracy for RPA: 0.8333333333333334\n",
      "\n",
      "C: 0.21544346900318845\n",
      "Training accuracy for RPA: 0.9678714859437751\n",
      "Test accuracy for RPA: 0.9814814814814815\n",
      "\n",
      "C: 0.7742636826811278\n",
      "Training accuracy for RPA: 0.9799196787148594\n",
      "Test accuracy for RPA: 0.9907407407407407\n",
      "\n",
      "C: 2.782559402207126\n",
      "Training accuracy for RPA: 0.9879518072289156\n",
      "Test accuracy for RPA: 0.9907407407407407\n",
      "\n",
      "C: 10.0\n",
      "Training accuracy for RPA: 1.0\n",
      "Test accuracy for RPA: 0.9907407407407407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = np.logspace(-4, 1, 10) \n",
    "for c in C:\n",
    "    model3 = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n",
    "    model3.fit(X_train, y_train)\n",
    "    #y_pred=model3.predict(X_test)\n",
    "    print('C:', c)\n",
    "    #print('Coefficient of each feature:', clf.coef_)\n",
    "    print('Training accuracy for RPA:', model3.score(X_train, y_train))\n",
    "    print('Test accuracy for RPA:', model3.score(X_test, y_test))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting for Dermatology Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for base model SGB: 0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "model4 = GradientBoostingClassifier(random_state=(0))\n",
    "model4.fit(X_train, y_train)\n",
    "y_pred = model4.predict(X_test)\n",
    "print(\"Accuracy for base model SGB:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'n_estimators': 250}\n",
      "Best score of the best model on training data: 0.9798367346938776\n"
     ]
    }
   ],
   "source": [
    "parameters = {'learning_rate':[0.2,0.15,0.1,0.05,0.01], 'n_estimators':[100,250,500,750]}\n",
    "\n",
    "tuning3 = GridSearchCV(estimator =GradientBoostingClassifier(max_features='sqrt', random_state=10), \n",
    "            param_grid = parameters, scoring='accuracy',n_jobs=4, cv=5)\n",
    "tuning3.fit(X_train,y_train)\n",
    "\n",
    "print(tuning3.best_params_)\n",
    "print(\"Best score of the best model on training data:\",tuning3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3}\n",
      "Best score of the best model on training data: 0.9798367346938776\n"
     ]
    }
   ],
   "source": [
    "max_depth = {'max_depth':[2,3,4,5] }\n",
    "tuning4 = GridSearchCV(estimator =GradientBoostingClassifier(learning_rate=0.01,n_estimators=250,max_features='sqrt', random_state=10), \n",
    "            param_grid = max_depth, scoring='accuracy',n_jobs=4, cv=5)\n",
    "tuning4.fit(X_train,y_train)\n",
    "print(tuning4.best_params_)\n",
    "print(\"Best score of the best model on training data:\",tuning4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Accuracy = % 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "best_model = GradientBoostingClassifier(learning_rate=0.01,n_estimators=250,max_features='sqrt',max_depth=3,random_state=10)\n",
    "best_model.fit(X_train,y_train)\n",
    "best_accuracy = evaluate(best_model, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABSENTEEISM DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Absenteeism_at_work.csv\",delimiter=';')\n",
    "\n",
    "\n",
    "data.iloc[:,1]=data.iloc[:,1].astype('category')\n",
    "data.iloc[:,3:5]=data.iloc[:,3:5].astype('category')\n",
    "data.iloc[:,11:13]=data.iloc[:,11:13].astype('category')\n",
    "data.iloc[:,14:16]=data.iloc[:,14:16].astype('category')\n",
    "zero_target_values=np.where(data['Absenteeism time in hours']==0)\n",
    "data.loc[zero_target_values[0],'Absenteeism time in hours']=0.00001\n",
    "\n",
    "features=data.columns[1:20]\n",
    "X = data.loc[:,features]\n",
    "y = data.loc[:,'Absenteeism time in hours'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    print('Model Performance')\n",
    "    print('Improved RMSE Error:',sqrt(mean_squared_error(test_labels,predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree for Absenteeism Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for base model DT: 17.467906364322907\n"
     ]
    }
   ],
   "source": [
    "model1 = DecisionTreeRegressor(random_state=(10))\n",
    "model1.fit(X_train, y_train)\n",
    "y_test_pred=model1.predict(X_test)\n",
    "#y_test_pred=y_test_pred.round()\n",
    "print('RMSE for base model DT:',sqrt(mean_squared_error(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters Tuning for DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_samples_leaf': 2}\n",
      "Best score of the best model on training data: 0.19692653399256793\n",
      "Model Performance\n",
      "Improved RMSE Error: 15.427723367254165\n"
     ]
    }
   ],
   "source": [
    "parameters = {'max_depth':[2,3,8,10], 'min_samples_leaf':[2,3,4,5]}\n",
    "\n",
    "tuning1 = GridSearchCV(estimator = DecisionTreeRegressor(random_state = 10), \n",
    "            param_grid = parameters,n_jobs=4, cv=5)\n",
    "tuning1.fit(X_train,y_train)\n",
    "\n",
    "print(tuning1.best_params_)\n",
    "print(\"Best score of the best model on training data:\",tuning1.best_score_)\n",
    "best_model1 = tuning1.best_estimator_\n",
    "best_model1_accuracy1 = evaluate(best_model1, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest for Absenteeism Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for base model RF: 15.012515148727063\n"
     ]
    }
   ],
   "source": [
    "model2 = RandomForestRegressor(random_state=(0))\n",
    "model2.fit(X_train, y_train)\n",
    "y_test_pred2=model2.predict(X_test)\n",
    "#y_test_pred2=y_test_pred2.round()\n",
    "print('RMSE for base model RF:',sqrt(mean_squared_error(y_test,y_test_pred2))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters Tuning for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 19}\n",
      "Best score of the best model on training data: 0.22091346815003457\n",
      "Model Performance\n",
      "Improved RMSE Error: 13.921751297593506\n"
     ]
    }
   ],
   "source": [
    "a=len(X.columns)\n",
    "b=round(math.sqrt(len(X.columns)))\n",
    "c=round((len(X.columns))/3)\n",
    "parameters = {'max_features': [a,b,c]}\n",
    "\n",
    "tuning2 = GridSearchCV(estimator=RandomForestRegressor(n_estimators=500,min_samples_leaf=5, random_state=0), \n",
    "            param_grid = parameters,n_jobs=4, cv=5)\n",
    "tuning2.fit(X_train,y_train)\n",
    "\n",
    "print(tuning2.best_params_)\n",
    "print(\"Best score of the best model on training data:\",tuning2.best_score_)\n",
    "best_random = tuning2.best_estimator_\n",
    "random_accuracy2 = evaluate(best_random, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRA for Absenteeism Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for PRA: 13.576178783371669\n",
      "best alpha: 0.05994842503189409\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-4, 1, 10)\n",
    "lassocv = linear_model.LassoCV(alphas=alphas,cv=5, random_state=0, max_iter = 2000)\n",
    "lassocv.fit(X_train, y_train)\n",
    "lassocv_score_on_train = lassocv.score(X_train, y_train)\n",
    "lassocv_score_on_test = lassocv.score(X_test, y_test)\n",
    "lassocv_alphas = lassocv.alphas_\n",
    "lassocv_alpha = lassocv.alpha_\n",
    "best_lasso = linear_model.Lasso(alpha=lassocv_alpha)\n",
    "best_lasso.fit(X_train, y_train)\n",
    "y_test_pred3=best_lasso.predict(X_test)\n",
    "print('RMSE for PRA:',sqrt(mean_squared_error(y_test,y_test_pred3)))\n",
    "print(\"best alpha:\",lassocv_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting for Absenteeism Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for base model SGB: 13.576178783371669\n"
     ]
    }
   ],
   "source": [
    "model4 = GradientBoostingRegressor(random_state=(0))\n",
    "model4.fit(X_train, y_train)\n",
    "y_pred = model4.predict(X_test)\n",
    "print(\"RMSE for base model SGB:\",sqrt(mean_squared_error(y_test,y_test_pred3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters Tuning for GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'n_estimators': 250}\n",
      "Best score of the best model on training data: 0.2182308659422282\n"
     ]
    }
   ],
   "source": [
    "parameters = {'learning_rate':[0.2,0.15,0.1,0.05,0.01], 'n_estimators':[100,250,500,750]}\n",
    "\n",
    "tuning3= GridSearchCV(estimator = model4, \n",
    "            param_grid = parameters,n_jobs=4, cv=5)\n",
    "tuning3.fit(X_train,y_train)\n",
    "\n",
    "print(tuning3.best_params_)\n",
    "print(\"Best score of the best model on training data:\",tuning3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3}\n",
      "Best score of the best model on training data: 0.2182308659422282\n"
     ]
    }
   ],
   "source": [
    "max_depth = {'max_depth':[2,3,4,5] }\n",
    "tuning4 = GridSearchCV(estimator =GradientBoostingRegressor(learning_rate=0.01,n_estimators=250, random_state=0), \n",
    "            param_grid = max_depth,n_jobs=4, cv=5)\n",
    "tuning4.fit(X_train,y_train)\n",
    "print(tuning4.best_params_)\n",
    "print(\"Best score of the best model on training data:\",tuning4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Improved RMSE Error: 14.833180992106856\n"
     ]
    }
   ],
   "source": [
    "best_model = GradientBoostingRegressor(learning_rate=0.01,n_estimators=250,max_depth=3,random_state=0)\n",
    "best_model.fit(X_train,y_train)\n",
    "best_accuracy = evaluate(best_model, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENERGY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"energydata_complete.csv\")\n",
    "\n",
    "names=data.columns[1:28]\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "d = scaler.fit_transform(data.iloc[:,1:28])\n",
    "data = pd.DataFrame(d, columns=names)\n",
    "\n",
    "features=data.columns[1:28]\n",
    "X = data.loc[:,features]\n",
    "y = data.loc[:,'Appliances'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    print('Model Performance')\n",
    "    print('Improved RMSE Error:',sqrt(mean_squared_error(test_labels,predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree for Energy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for base model DT: 0.08948136705626476\n"
     ]
    }
   ],
   "source": [
    "model1 = DecisionTreeRegressor(random_state=(0))\n",
    "model1.fit(X_train, y_train)\n",
    "y_test_pred=model1.predict(X_test)\n",
    "print('RMSE for base model DT:',sqrt(mean_squared_error(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters Tuning for DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_samples_leaf': 5}\n",
      "Model Performance\n",
      "Improved RMSE Error: 0.08323374247961722\n"
     ]
    }
   ],
   "source": [
    "parameters = {'max_depth':[2,3,8,10], 'min_samples_leaf':[2,3,4,5]}\n",
    "\n",
    "tuning1 = GridSearchCV(estimator = DecisionTreeRegressor(random_state = 10), \n",
    "            param_grid = parameters,n_jobs=4, cv=5)\n",
    "tuning1.fit(X_train,y_train)\n",
    "\n",
    "print(tuning1.best_params_)\n",
    "best_model1 = tuning1.best_estimator_\n",
    "best_model_accuracy1 = evaluate(best_model1, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest for Energy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for base model RF: 0.06622667194489702\n"
     ]
    }
   ],
   "source": [
    "model2 = RandomForestRegressor(random_state=(0))\n",
    "model2.fit(X_train, y_train)\n",
    "y_test_pred2=model2.predict(X_test)\n",
    "print('RMSE for base model RF:',sqrt(mean_squared_error(y_test,y_test_pred2))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters Tuning for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 9}\n",
      "Model Performance\n",
      "Improved RMSE Error: 0.06950470010017393\n"
     ]
    }
   ],
   "source": [
    "a=len(X.columns)\n",
    "b=round(math.sqrt(len(X.columns)))\n",
    "c=round((len(X.columns))/3)\n",
    "parameters = {'max_features': [a,b,c]}\n",
    "\n",
    "tuning2 = GridSearchCV(estimator=RandomForestRegressor(n_estimators=500,min_samples_leaf=5, random_state=0), \n",
    "            param_grid = parameters,n_jobs=4, cv=5)\n",
    "tuning2.fit(X_train,y_train)\n",
    "\n",
    "print(tuning2.best_params_)\n",
    "\n",
    "best_model2 = tuning2.best_estimator_\n",
    "best_model_accuracy2 = evaluate(best_model2, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRA for Energy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for PRA: 0.08719947670931776\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-4, 1, 10)\n",
    "lassocv = linear_model.LassoCV(alphas=alphas,cv=5, random_state=0, max_iter = 2000)\n",
    "lassocv.fit(X_train, y_train)\n",
    "lassocv_score_on_train = lassocv.score(X_train, y_train)\n",
    "lassocv_score_on_test = lassocv.score(X_test, y_test)\n",
    "lassocv_alphas = lassocv.alphas_\n",
    "lassocv_alpha = lassocv.alpha_\n",
    "best_lasso = linear_model.Lasso(alpha=lassocv_alpha)\n",
    "best_lasso.fit(X_train, y_train)\n",
    "y_test_pred3=best_lasso.predict(X_test)\n",
    "print('RMSE for PRA:',sqrt(mean_squared_error(y_test,y_test_pred3))) \n",
    "print(lassocv_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting for Energy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for base model SGB: 0.08719947670931776\n"
     ]
    }
   ],
   "source": [
    "model4 = GradientBoostingRegressor(random_state=(0))\n",
    "model4.fit(X_train, y_train)\n",
    "y_pred = model4.predict(X_test)\n",
    "print(\"RMSE for base model SGB:\",sqrt(mean_squared_error(y_test,y_test_pred3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters Tuning for GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.15, 'n_estimators': 750}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'learning_rate':[0.2,0.15,0.1,0.05,0.01], 'n_estimators':[100,250,500,750]}\n",
    "\n",
    "tuning3= GridSearchCV(estimator = model4, \n",
    "            param_grid = parameters,n_jobs=4, cv=5)\n",
    "tuning3.fit(X_train,y_train)\n",
    "\n",
    "print(tuning3.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "max_depth = {'max_depth':[2,3,4,5] }\n",
    "tuning4 = GridSearchCV(estimator =GradientBoostingRegressor(learning_rate = tuning3.best_params_['learning_rate'], n_estimators = tuning3.best_params_['n_estimators'], random_state=0), \n",
    "            param_grid = max_depth,n_jobs=4, cv=5)\n",
    "tuning4.fit(X_train,y_train)\n",
    "print(tuning4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Improved RMSE Error: 0.06658608892560446\n"
     ]
    }
   ],
   "source": [
    "best_model4 = GradientBoostingRegressor(learning_rate = tuning3.best_params_['learning_rate'], n_estimators = tuning3.best_params_['n_estimators'], max_depth = tuning4.best_params_['max_depth'],random_state=0)\n",
    "best_model4.fit(X_train,y_train)\n",
    "best_accuracy = evaluate(best_model4, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONLINE NEWS POPULARITY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"OnlineNewsPopularity.csv\")\n",
    "shares_below_1400=np.where(data[' shares']<1400)\n",
    "shares_above_1400=np.where(data[' shares']>=1400)\n",
    "data.loc[shares_below_1400[0],' shares']=0\n",
    "data.loc[shares_above_1400[0],' shares']=1\n",
    "names=data.columns[1:61]\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "d = scaler.fit_transform(data.iloc[:,1:61])\n",
    "data = pd.DataFrame(d, columns=names)\n",
    "data.iloc[:,12:18]=data.iloc[:,12:18].astype('category')\n",
    "data.iloc[:,30:38]=data.iloc[:,30:38].astype('category')\n",
    "\n",
    "features=data.columns[:59]\n",
    "X = data[features]\n",
    "y = data.loc[:,' shares']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30,random_state=42)\n",
    "y_test=y_test.to_numpy()\n",
    "y_train=y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    print('Model Performance')\n",
    "    print('Improved Accuracy = {:0.2f}%.',metrics.accuracy_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree for Online News Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for base model DT: 0.5875231209012948\n"
     ]
    }
   ],
   "source": [
    "model1 = DecisionTreeClassifier(random_state=0)\n",
    "model1.fit(X_train, y_train)\n",
    "y_test_pred=model1.predict(X_test)\n",
    "#Score the model\n",
    "print(\"Accuracy for base model DT:\",metrics.accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters Tuning for DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 8, 'min_samples_leaf': 4}\n",
      "Best score of the best model on training data: 0.6388468468468467\n",
      "Model Performance\n",
      "Improved Accuracy = {:0.2f}%. 0.633176391457878\n"
     ]
    }
   ],
   "source": [
    "parameters = {'max_depth':[2,3,8,10], 'min_samples_leaf':[2,3,4,5]}\n",
    "\n",
    "tuning1 = GridSearchCV(estimator = DecisionTreeClassifier(random_state = 0), \n",
    "            param_grid = parameters, scoring='accuracy',n_jobs=4, cv=5)\n",
    "tuning1.fit(X_train,y_train)\n",
    "\n",
    "print(tuning1.best_params_)\n",
    "print(\"Best score of the best model on training data:\",tuning1.best_score_)\n",
    "best_model1 = tuning1.best_estimator_\n",
    "best_model1_accuracy1 = evaluate(best_model1, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest for Online News Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for RF: 0.6657138052799731\n"
     ]
    }
   ],
   "source": [
    "model2=RandomForestClassifier(random_state=0)\n",
    "model2.fit(X_train, y_train)\n",
    "y_train_pred2=model2.predict(X_train)\n",
    "y_test_pred2=model2.predict(X_test)\n",
    "\n",
    "# Score the model\n",
    "print(\"Accuracy for RF:\",metrics.accuracy_score(y_test, y_test_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters Tuning for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 8}\n",
      "Best score of the best model on training data: 0.6756756756756757\n",
      "Model Performance\n",
      "Improved Accuracy = {:0.2f}%. 0.6742895577602153\n"
     ]
    }
   ],
   "source": [
    "a=len(X.columns)\n",
    "b=round(math.sqrt(len(X.columns)))\n",
    "c=round((len(X.columns))/3)\n",
    "parameters = {'max_features': [a,b,c]}\n",
    "\n",
    "tuning2 = GridSearchCV(estimator=RandomForestClassifier(n_estimators=500,min_samples_leaf=5, random_state=0), \n",
    "            param_grid = parameters, scoring='accuracy',n_jobs=4, cv=5)\n",
    "tuning2.fit(X_train,y_train)\n",
    "\n",
    "print(tuning2.best_params_)\n",
    "print(\"Best score of the best model on training data:\",tuning2.best_score_)\n",
    "\n",
    "best_random = tuning2.best_estimator_\n",
    "random_accuracy2 = evaluate(best_random, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RPA for Online News Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.0001\n",
      "Training accuracy for RPA: 0.4648288288288288\n",
      "Test accuracy for RPA: 0.47006894232386076\n",
      "\n",
      "C: 0.00035938136638046257\n",
      "Training accuracy for RPA: 0.4648288288288288\n",
      "Test accuracy for RPA: 0.47006894232386076\n",
      "\n",
      "C: 0.001291549665014884\n",
      "Training accuracy for RPA: 0.5351711711711712\n",
      "Test accuracy for RPA: 0.5299310576761392\n",
      "\n",
      "C: 0.004641588833612782\n",
      "Training accuracy for RPA: 0.624072072072072\n",
      "Test accuracy for RPA: 0.6217420548175551\n",
      "\n",
      "C: 0.016681005372000592\n",
      "Training accuracy for RPA: 0.6346666666666667\n",
      "Test accuracy for RPA: 0.6320834033966706\n",
      "\n",
      "C: 0.05994842503189409\n",
      "Training accuracy for RPA: 0.6467027027027027\n",
      "Test accuracy for RPA: 0.6422565999663696\n",
      "\n",
      "C: 0.21544346900318845\n",
      "Training accuracy for RPA: 0.6523603603603604\n",
      "Test accuracy for RPA: 0.6454514881452833\n",
      "\n",
      "C: 0.7742636826811278\n",
      "Training accuracy for RPA: 0.6556036036036036\n",
      "Test accuracy for RPA: 0.6488986043383218\n",
      "\n",
      "C: 2.782559402207126\n",
      "Training accuracy for RPA: 0.6568648648648648\n",
      "Test accuracy for RPA: 0.6510005044560282\n",
      "\n",
      "C: 10.0\n",
      "Training accuracy for RPA: 0.6573693693693694\n",
      "Test accuracy for RPA: 0.6504119724230705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = np.logspace(-4, 1, 10) \n",
    "for c in C:\n",
    "    model3 = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n",
    "    model3.fit(X_train, y_train)\n",
    "    print('C:', c)\n",
    "    #print('Coefficient of each feature:', clf.coef_)\n",
    "    print('Training accuracy for RPA:', model3.score(X_train, y_train))\n",
    "    print('Test accuracy for RPA:', model3.score(X_test, y_test))\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting for Online News Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for base model SGB: 0.6658819572893896\n"
     ]
    }
   ],
   "source": [
    "model4 = GradientBoostingClassifier(random_state=(0))\n",
    "model4.fit(X_train, y_train)\n",
    "y_pred = model4.predict(X_test)\n",
    "print(\"Accuracy for base model SGB:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters Tuning for GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'n_estimators': 250}\n",
      "Best score of the best model on training data: 0.6780180180180182\n"
     ]
    }
   ],
   "source": [
    "parameters = {'learning_rate':[0.2,0.15,0.1,0.05,0.01], 'n_estimators':[100,250,500,750]}\n",
    "\n",
    "tuning3= GridSearchCV(estimator =GradientBoostingClassifier(max_features='sqrt', random_state=10), \n",
    "            param_grid = parameters, scoring='accuracy',n_jobs=4, cv=5)\n",
    "tuning3.fit(X_train,y_train)\n",
    "\n",
    "print(tuning3.best_params_)\n",
    "print(\"Best score of the best model on training data:\",tuning3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3}\n",
      "Best score of the best model on training data: 0.6780180180180182\n"
     ]
    }
   ],
   "source": [
    "max_depth = {'max_depth':[2,3,4,5] }\n",
    "tuning4 = GridSearchCV(estimator =GradientBoostingClassifier(learning_rate=0.1,n_estimators=250,max_features='sqrt', random_state=10), \n",
    "            param_grid = max_depth, scoring='accuracy',n_jobs=4, cv=5)\n",
    "tuning4.fit(X_train,y_train)\n",
    "print(tuning4.best_params_)\n",
    "print(\"Best score of the best model on training data:\",tuning4.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Improved Accuracy = {:0.2f}%. 0.6705061375483437\n"
     ]
    }
   ],
   "source": [
    "best_model = GradientBoostingClassifier(learning_rate=0.1,n_estimators=250,max_features='sqrt',max_depth=3,random_state=10)\n",
    "best_model.fit(X_train,y_train)\n",
    "best_accuracy = evaluate(best_model, X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
